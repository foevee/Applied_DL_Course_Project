{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "assign5_2_image_color_GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rF2x3qooyBTI"
      },
      "source": [
        "# Image Colorization Model using Generative Adversarial Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2MbKJY38Puy9"
      },
      "source": [
        "## Definition of GAN\n",
        "[Generative Adversarial Networks](https://arxiv.org/abs/1406.2661) (GANs) are one of the most interesting ideas in computer science today. Two models are trained simultaneously by an adversarial process. A *generator* (\"the artist\") learns to create images that look real, while a *discriminator* (\"the art critic\") learns to tell real images apart from fakes.\n",
        "\n",
        "\n",
        "During training, the *generator* progressively becomes better at creating images that look real, while the *discriminator* becomes better at telling them apart. The process reaches equilibrium when the *discriminator* can no longer distinguish real images from fakes.\n",
        "\n",
        "\n",
        "In this notebook, we will use GAN process to colorize the images on the CIFAR-10 dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e1_Y75QXJS6h"
      },
      "source": [
        "### Import TensorFlow and other libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WZKbyU2-AiY-",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YzTlj4YdCip_",
        "colab": {}
      },
      "source": [
        "# To generate GIFs\n",
        "!pip install -q imageio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YfIk2es3hJEd",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import PIL\n",
        "import time\n",
        "import pickle\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from skimage import color, io\n",
        "from tensorflow.keras import layers\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, BatchNormalization, \\\n",
        "     UpSampling2D, Dropout, Flatten, Dense, Input, LeakyReLU, Conv2DTranspose, \\\n",
        "     AveragePooling2D, Concatenate, Dot\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iYn4MdZnKCey"
      },
      "source": [
        "### Load and prepare the dataset\n",
        "\n",
        "We use the CIFAR-10 dataset to train the generator and the discriminator. The generator will generate the images resembling the 10-classes data. Since we are trying to colorize images, we will only use images data to split into X_train, Y_train, X_test, Y_test. The X is the 1-channel grey color data, and the Y is the 3-channel RGB data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a4fYMGxGhrna",
        "colab": {}
      },
      "source": [
        "#For this image colorization, we care about images but not labels\n",
        "(train_images, _), (test_images, _) = tf.keras.datasets.cifar10.load_data()\n",
        "train_images.shape, test_images.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NFC2ghIdiZYE",
        "colab": {}
      },
      "source": [
        "#we will merge the 3 channel RGB colors into 1 single color\n",
        "#add the 3 channel together and rescale the image data to 0-1 to get X\n",
        "X_train = np.sum(train_images ,axis=-1)/(3*255)  \n",
        "X_test=np.sum(test_images, axis=-1)/(3*255)\n",
        "\n",
        "Y_train = train_images/255\n",
        "Y_test = test_images/255\n",
        "\n",
        "#rescale Y_train from [0,1] range to [-1,1]\n",
        "Y_train = 2*Y_train-1\n",
        "\n",
        "#re-shape\n",
        "X_train=X_train.reshape(train_images.shape[0], 32, 32, 1)\n",
        "X_test=X_test.reshape(test_images.shape[0], 32, 32, 1)\n",
        "\n",
        "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "THY-sZMiQ4UV"
      },
      "source": [
        "## Create the models\n",
        "\n",
        "Both the generator and discriminator are defined using the [Keras Sequential API](https://www.tensorflow.org/guide/keras#sequential_model)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55bABN77PY8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_shape = (32,32,1)\n",
        "y_shape = (32,32,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-tEyxE-GMC48"
      },
      "source": [
        "### The Generator\n",
        "\n",
        "The generator uses `Conv2DTranspose` (upsampling) layers to produce an image from a seed (random noise). Start with a `Dense` layer that takes this seed as input, then upsample several times until you reach the desired image size of 28x28x1. Notice the `LeakyReLU` activation for each layer, except the output layer which uses tanh."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6bpTcDqoLWjY",
        "colab": {}
      },
      "source": [
        "def generator_model(verbose=False):\n",
        "    #since we need to use the reference of each layers later\n",
        "    #so we do not use model.add\n",
        "\n",
        "    ## 1. Encoder\n",
        "    #32*32\n",
        "    gen_input = Input(shape=x_shape)\n",
        "    conv1 = Conv2D(64, (1, 1), padding='same', strides=1)(gen_input)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    conv1 = LeakyReLU(0.2)(conv1)\n",
        "    #print(\"1\", conv1.shape)\n",
        "\n",
        "    #32*32\n",
        "    conv2 = Conv2D(128, (2, 2), padding='same', strides=1)(conv1)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = LeakyReLU(0.2)(conv2)\n",
        "    #print(\"2\", conv2.shape)\n",
        "\n",
        "    #16*16\n",
        "    conv3 = Conv2D(128, (2, 2), padding='same', strides=2)(conv2)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    conv3 = LeakyReLU(0.2)(conv3)\n",
        "    #print(\"3\", conv3.shape)\n",
        "\n",
        "    #16 * 16\n",
        "    conv4 = Conv2D(256, (2, 2), padding='same', strides=1)(conv3)\n",
        "    conv4 = BatchNormalization()(conv4)\n",
        "    conv4 = LeakyReLU(0.2)(conv4)\n",
        "    #print(\"4\", conv4.shape)\n",
        "\n",
        "    #8 * 8\n",
        "    conv5 = Conv2D(512, (2, 2), padding='same', strides=2)(conv4)\n",
        "    conv5 = BatchNormalization()(conv5)\n",
        "    conv5 = LeakyReLU(0.2)(conv5)\n",
        "    #print(\"5\", conv5.shape)\n",
        "    \n",
        "    \n",
        "    ## 2. Decoder\n",
        "    #start to use de-convolutoin, i.e. transposed convolution layer \n",
        "    # (we can also use upsampling to get the same result)\n",
        "    #16 * 16\n",
        "    deconv6 = Conv2DTranspose(256, (2,2), padding='same', strides=2)(conv5)\n",
        "    deconv6 = BatchNormalization()(deconv6)\n",
        "    deconv6 = LeakyReLU(0.2)(deconv6)\n",
        "    deconv6 = Dropout(0.4)(deconv6)\n",
        "    deconv6 = Concatenate(axis=3)([deconv6,conv4])  #concatenate on the last dim\n",
        "    #print(\"6\", deconv6.shape)\n",
        "\n",
        "    #16 * 16\n",
        "    deconv7 = Conv2DTranspose(256, (2,2), padding='same', strides=1)(deconv6)\n",
        "    deconv7 = BatchNormalization()(deconv7)\n",
        "    deconv7 = LeakyReLU(0.2)(deconv7)\n",
        "    deconv7 = Dropout(0.4)(deconv7)\n",
        "    deconv7 = Concatenate(axis=-1)([deconv7,conv3])  #concatenate on the last dim\n",
        "    #print(\"7\", deconv7.shape)\n",
        "\n",
        "    #32 * 32\n",
        "    deconv8 = Conv2DTranspose(128, (2,2), padding='same', strides=2)(deconv7)\n",
        "    deconv8 = BatchNormalization()(deconv8)\n",
        "    deconv8 = LeakyReLU(0.2)(deconv8)\n",
        "    deconv8 = Dropout(0.2)(deconv8)\n",
        "    deconv8 = Concatenate(axis=-1)([deconv8,conv2])  #concatenate on the last dim\n",
        "    #print(\"8\", deconv8.shape)\n",
        "\n",
        "    #32 * 32\n",
        "    deconv9 = Conv2DTranspose(64, (2,2), padding='same', strides=1)(deconv8)\n",
        "    deconv9 = BatchNormalization()(deconv9)\n",
        "    deconv9 = LeakyReLU(0.2)(deconv9)\n",
        "    deconv9 = Dropout(0.4)(deconv9)\n",
        "    deconv9 = Concatenate(axis=-1)([deconv9,conv1])  #concatenate on the last dim\n",
        "    #print(\"9\", deconv9.shape)\n",
        "\n",
        "    #last one convolution layer\n",
        "    #output is for 3 colors (not classiy 10 labels)\n",
        "    conv10 = Conv2D(3, (1, 1), padding='same', strides=1, activation='tanh')(deconv9)  \n",
        "    model = Model(inputs = gen_input, outputs=conv10)\n",
        "\n",
        "    if(verbose):\n",
        "        print(model.summary())\n",
        "    return model   \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D0IKnaCtg6WE"
      },
      "source": [
        "### The Discriminator\n",
        "\n",
        "The discriminator is a CNN-based image classifier with two concatenated variables as input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dw2tPLmk2pEP",
        "colab": {}
      },
      "source": [
        "def discriminator_model(verbose=False):\n",
        "\n",
        "    #since we need to concatenate, still use functional API\n",
        "    X = Input(shape = x_shape)\n",
        "    Y = Input(shape = y_shape)\n",
        "    dis_input = Concatenate(axis=-1)([X,Y])\n",
        "    \n",
        "    conv1 = Conv2D(32, (2,2), strides = 2)(dis_input)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    conv1 = LeakyReLU(0.2)(conv1)\n",
        "    \n",
        "    conv2 = Conv2D(64, (2,2), strides = 2)(conv1)  \n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = LeakyReLU(0.2)(conv2)\n",
        "  \n",
        "    conv3 = Conv2D(128, (2,2), strides = 2)(conv2)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    conv3 = LeakyReLU(0.2)(conv3)\n",
        "  \n",
        "    conv4 = Conv2D(128, (2,2), strides = 1)(conv3)\n",
        "    conv4 = BatchNormalization()(conv4)\n",
        "    conv4 = LeakyReLU(0.2)(conv4)\n",
        "  \n",
        "    dense5 = Flatten()(conv4)\n",
        "    dense5 = Dense(128)(dense5)\n",
        "    dense5 = Dense(1,activation='sigmoid')(dense5)\n",
        "  \n",
        "    model = Model([X,Y], dense5)\n",
        "    if verbose:\n",
        "        print(model.summary())\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QhPneagzCaQv"
      },
      "source": [
        "### Define the combined model\n",
        "\n",
        "Use the (as yet untrained) generator and discriminator to define the combined model. The model will be trained to generate images which are finally like the real images. We use cosine distance to measure the loss and evaluate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gDkA05NE6QMs",
        "colab": {}
      },
      "source": [
        "X = Input(shape = x_shape)\n",
        "Y = Input(shape = y_shape)\n",
        "\n",
        "generator = generator_model()\n",
        "discriminator = discriminator_model()\n",
        "X_gen = generator(X)\n",
        "Y_disc = discriminator([X, X_gen])\n",
        "\n",
        "X_gen_flat = Flatten()(X_gen) #generated images\n",
        "Y_flat = Flatten()(Y)  #real images\n",
        "\n",
        "cosine_distance = Dot(axes=1, normalize=True)([X_gen_flat, Y_flat])\n",
        "combined = Model([X,Y], [Y_disc, cosine_distance])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW3k7Fpi_pDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "8b4c9b96-c6c0-4875-e29d-56cb4d78d4dc"
      },
      "source": [
        "combined.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_1 (Model)                 (None, 32, 32, 3)    2073795     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 3072)         0           model_1[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 3072)         0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "model_2 (Model)                 (None, 1)            256481      input_1[0][0]                    \n",
            "                                                                 model_1[1][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 1)            0           flatten_2[0][0]                  \n",
            "                                                                 flatten_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,330,276\n",
            "Trainable params: 2,325,988\n",
            "Non-trainable params: 4,288\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0FMYgY_mPfTi"
      },
      "source": [
        "## Define the loss and optimizers\n",
        "\n",
        "Define loss functions and optimizers for both models. The discriminator and the generator optimizers are different since we will train two networks separately.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF6UL6X4G6Tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer = Adam(lr = 0.0001))\n",
        "combined.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = 0.0001))  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Rw1fkAczTQYh"
      },
      "source": [
        "## Define the training loop\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NS2GWywBbAWo",
        "colab": {}
      },
      "source": [
        "epochs = 20\n",
        "train_size = 50000\n",
        "batch_size = 256\n",
        "\n",
        "genLoss=[]\n",
        "discLoss=[]\n",
        "\n",
        "batches = int(train_size / batch_size)\n",
        "disc_updates = 2  #each time discrimator model has 2 inputs, need to train twice\n",
        "gen_updates = 1\n",
        "\n",
        "#zero and one used for cross entropy loss calculation\n",
        "zeros=np.zeros((batch_size,1))\n",
        "ones=np.ones((batch_size,1))*0.9\n",
        "disc_loss_factor = batches*2*disc_updates\n",
        "gen_loss_factor = batches*gen_updates\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jylSonrqSWfi"
      },
      "source": [
        "The training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3GBQALEIYGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_size = 50000\n",
        "test_size = 10000\n",
        "batch_size = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2M7LmLtGEMQJ",
        "colab": {}
      },
      "source": [
        "def train(x_data, y_data, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "        print(\"#################\")\n",
        "        print(\"For Epoch:\"+str(epoch))\n",
        "        gen_loss = 0\n",
        "        disc_loss = 0\n",
        "\n",
        "        print(\"Training Discriminator\")\n",
        "        index = shuffle(range(train_size))\n",
        "\n",
        "        discriminator.compile(loss=\"binary_crossentropy\", optimizer = Adam(lr = 0.0001))\n",
        "        discriminator.trainable = True\n",
        "        for i in range(disc_updates):  \n",
        "            for b in range(batches):\n",
        "                train_range = index[b*batch_size:(b+1)*batch_size]\n",
        "                x_batch = x_data[train_range]\n",
        "                y_batch = y_data[train_range]\n",
        "                pred_batch = generator.predict(x_batch)\n",
        "\n",
        "                #discriminator has two loss\n",
        "                disc_loss += discriminator.train_on_batch([x_batch,y_batch],ones)\n",
        "                disc_loss += discriminator.train_on_batch([x_batch,pred_batch],zeros)\n",
        "      \n",
        "        print(\"Training Generator\")\n",
        "        discriminator.trainable = False\n",
        "        combined.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = 0.0001))  \n",
        "        discriminator.compile(loss = \"binary_crossentropy\",optimizer = Adam(lr = 0.0001))\n",
        "        for  i in range(gen_updates):\n",
        "            for b in range(batches):\n",
        "                train_range = index[b*batch_size:(b+1)*batch_size]\n",
        "                x_batch = x_data[train_range]\n",
        "                y_batch = y_data[train_range]\n",
        "      \n",
        "                loss, _ , _ = combined.train_on_batch([x_batch,y_batch],[ones,ones])\n",
        "                gen_loss += loss\n",
        "      \n",
        "        gen_loss /= gen_loss_factor\n",
        "        disc_loss /= disc_loss_factor\n",
        "        genLoss.append(gen_loss)\n",
        "        discLoss.append(disc_loss)\n",
        "        print(f\"Discriminator Loss: {disc_loss}\")\n",
        "        print(f\"Generator loss: {gen_loss}\")\n",
        "        \n",
        "        generate_and_save_images(generator, epoch, x_data, y_data)\n",
        "        #\n",
        "        #x_img = x_data[rand_idx]\n",
        "        #pred_img = (generator.predict(x_img)+1)/2 #return [-1,1] back to [0,1], generated images\n",
        "        #real_img = (y_data[rand_idx]+1)/2  \n",
        "        #fig = plot(x_img, pred_img, real_img, 3)\n",
        "        #plt.show()\n",
        "        #plt.close(fig)\n",
        "    \n",
        "    return genLoss, discLoss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2aFF7Hk3XdeW"
      },
      "source": [
        "**Generate and save images**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RmdVsmvhPxyy",
        "colab": {}
      },
      "source": [
        "def generate_and_save_images(model, epoch, x_data, y_data, is_train=True):\n",
        "    # Notice `training` is set to False.\n",
        "    # This is so all layers run in inference mode (batchnorm).\n",
        "    if is_train:\n",
        "        rand_idx = np.random.randint(train_size, size=3) #pick 3 images\n",
        "    else:\n",
        "        rand_idx = np.random.randint(test_size, size=3) #pick 3 images\n",
        "    x_images = x_data[rand_idx]\n",
        "    predictions = model.predict(x_images)\n",
        "    pred_images = (predictions+1)/2\n",
        "    real_images = (y_data[rand_idx]+1)/2\n",
        "    \n",
        "    samples = [x_images, pred_images, real_images]\n",
        "    fig = plt.figure(figsize=(6,6))\n",
        "    k=0\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            k += 1\n",
        "            ax = plt.subplot(3,3,k)\n",
        "            plt.axis('off')\n",
        "            ax.set_aspect('equal')\n",
        "            if samples[i][j].shape == (32,32,1):\n",
        "                plt.imshow(samples[i][j].reshape(32, 32))\n",
        "            else:\n",
        "                plt.imshow(samples[i][j].reshape(32,32,3))\n",
        "\n",
        "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dZrd4CdjR-Fp"
      },
      "source": [
        "## Train the model\n",
        "Call the `train()` method defined above to train the generator and discriminator simultaneously. Note, training GANs can be tricky. It's important that the generator and discriminator do not overpower each other (e.g., that they train at a similar rate).\n",
        "\n",
        "At the beginning of the training, the generated images look like very vague and fuzzy. As training progresses, the generated digits will look increasingly real. After about 50 epochs, they resemble CIFAR-10 images. This may take about two minute / epoch with the default settings on Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ly3UN0SLLY2l",
        "colab": {}
      },
      "source": [
        "genLoss, discLoss = train(X_train, Y_train, epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnKOBxFBXnoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nJHiHiZanIR",
        "colab_type": "text"
      },
      "source": [
        "In each picture, there are 3 random images being picked to plot in each column. While for a fixed column (image), three rows from the top to the botton are the `single-color images (1-channel), generated images, and the real_images`. We can see than with epochs growing, the generated images are looked increasingly real and clear and much more like the real images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mxh4kATPkXW",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate the model\n",
        "We plot the history of the model training loss and further see the model performance on the see data to evaluate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgN2U_C6PeS2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "170c96b1-eef7-4836-ef70-0f5de1dfc39e"
      },
      "source": [
        "#Plot the model loss history to evaluate\n",
        "plt.plot(genLoss, c='r', label=\"Generator Loss\")\n",
        "plt.plot(discLoss, c='b', label=\"Discriminator Loss\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxvoGPDNDOg-",
        "colab_type": "text"
      },
      "source": [
        "We can see both generator loss and the discriminator loss decrease with time, which means that the model performs well on the training set. Furthermore, we can evaluate the model on the test set by picking some random test data and plot the predictions from the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BigPJcgCbs3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate_and_save_images(generator, 0, X_test, Y_test, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH_6eVNQb0Nf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}